{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "RAW_PATH = \"../RawData\"\n",
    "OUT_PATH = \"./MFCC\"\n",
    "THREADS = 80"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原始資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_CASIA = np.load('CASIA.npy', allow_pickle=True)\n",
    "np_EMODB = np.load('EMODB.npy', allow_pickle=True)\n",
    "np_MERGE_TRAIN = np.load('MERGE_TRAIN.npy', allow_pickle=True)\n",
    "np_IEMOCAP = np.load('IEMOCAP.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape    (20310, 254, 39)\n",
      "y shape    (5531, 4)\n"
     ]
    }
   ],
   "source": [
    "dict_CASIA = np_CASIA.item()\n",
    "dict_EMODB = np_EMODB.item()\n",
    "dict_MERGE_TRAIN = np_MERGE_TRAIN.item()\n",
    "dict_IEMOCAP = np_IEMOCAP.item()\n",
    "x, y = dict_MERGE_TRAIN['x'], dict_IEMOCAP['y']\n",
    "print(f'{\"X shape\":10}', x.shape)\n",
    "print(f'{\"y shape\":10}', y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將 mp4 轉換成 wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp42wav(filename):\n",
    "    ObjPath = Path(filename)\n",
    "    filename_wo = str(ObjPath.parent.joinpath(ObjPath.stem))\n",
    "    # print(f\"ffmpeg -loglevel error -i {filename_wo}.mp4 -ar:a 0 -vn -y {filename_wo}.wav\")\n",
    "    os.system(f\"ffmpeg -loglevel error -i {filename_wo}.mp4 -ar:a 0 -vn -y {filename_wo}.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mp42wav:  43%|████▎     | 5932/13848 [00:39<00:56, 140.92it/s][mov,mp4,m4a,3gp,3g2,mj2 @ 0x55cc21461740] moov atom not found\n",
      "../RawData/meld_part1/dia125_utt3.mp4: Invalid data found when processing input\n",
      "mp42wav: 100%|██████████| 13848/13848 [01:26<00:00, 159.75it/s]\n"
     ]
    }
   ],
   "source": [
    "ls_mp4 = glob(os.path.join(RAW_PATH, 'meld_part*/*.mp4'))\n",
    "pool = Pool(THREADS)\n",
    "r = list(tqdm(pool.imap(mp42wav, ls_mp4), desc='mp42wav: ', total=len(ls_mp4)))\n",
    "\n",
    "# for mp4_file in tqdm(ls_mp4, desc=\"mp42wav: \"):\n",
    "#     mp42wav(mp4_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前處理新資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(file_path: str, mfcc_len: int=39, mean_signal_length: int=130000):\n",
    "    signal, fs = librosa.load(file_path)\n",
    "    s_len = len(signal)\n",
    "    \n",
    "    if s_len < mean_signal_length:\n",
    "        pad_len = mean_signal_length - s_len\n",
    "        pad_rem = pad_len % 2\n",
    "        pad_len //= 2\n",
    "        signal = np.pad(signal, (pad_len, pad_len + pad_rem), 'constant', constant_values=0)\n",
    "    else:\n",
    "        pad_len = s_len - mean_signal_length\n",
    "        pad_len //= 2\n",
    "        signal = signal[pad_len: pad_len + mean_signal_length]\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=signal, sr=fs, n_mfcc=mfcc_len).T\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_map = pd.read_csv(os.path.join(RAW_PATH, 'train_data.csv'))\n",
    "df_test_map = pd.read_csv(os.path.join(RAW_PATH, 'test_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_map['name'] = df_train_map['name'].str.replace('.mp4', '.wav', regex=False)\n",
    "df_test_map['name'] = df_test_map['name'].str.replace('.mp4', '.wav', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     6413\n",
       "happy       3337\n",
       "angry       2776\n",
       "sad         2292\n",
       "surprise    1782\n",
       "disgust     1779\n",
       "fear        1777\n",
       "calm         154\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_map['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crema_d</td>\n",
       "      <td>1003_TAI_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ravdess</td>\n",
       "      <td>03-01-03-02-01-02-11.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meld_part1</td>\n",
       "      <td>dia551_utt3.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ravdess</td>\n",
       "      <td>03-01-07-01-01-02-09.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meld_part1</td>\n",
       "      <td>dia1013_utt2.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20305</th>\n",
       "      <td>ravdess</td>\n",
       "      <td>03-01-02-01-01-01-19.wav</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20306</th>\n",
       "      <td>ravdess</td>\n",
       "      <td>03-01-06-02-01-01-18.wav</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20307</th>\n",
       "      <td>tess</td>\n",
       "      <td>OAF_phone_happy.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20308</th>\n",
       "      <td>meld_part1</td>\n",
       "      <td>dia640_utt13.wav</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20309</th>\n",
       "      <td>crema_d</td>\n",
       "      <td>1067_IEO_ANG_MD.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20310 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                      name  emotion\n",
       "0         crema_d       1003_TAI_DIS_XX.wav  disgust\n",
       "1         ravdess  03-01-03-02-01-02-11.wav    happy\n",
       "2      meld_part1           dia551_utt3.wav    happy\n",
       "3         ravdess  03-01-07-01-01-02-09.wav  disgust\n",
       "4      meld_part1          dia1013_utt2.wav  neutral\n",
       "...           ...                       ...      ...\n",
       "20305     ravdess  03-01-02-01-01-01-19.wav     calm\n",
       "20306     ravdess  03-01-06-02-01-01-18.wav     fear\n",
       "20307        tess       OAF_phone_happy.wav    happy\n",
       "20308  meld_part1          dia640_utt13.wav  neutral\n",
       "20309     crema_d       1067_IEO_ANG_MD.wav    angry\n",
       "\n",
       "[20310 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'calm' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
      "[array([0, 1, 2, 3, 4, 5, 6, 7])]\n"
     ]
    }
   ],
   "source": [
    "lbec = LabelEncoder().fit(df_train_map['emotion'])\n",
    "df_train_map['emotion'] = lbec.transform(df_train_map['emotion'])\n",
    "df_test_map['emotion'] = lbec.transform(df_test_map['emotion'])\n",
    "print(lbec.classes_)\n",
    "\n",
    "ohec = OneHotEncoder().fit(df_train_map[['emotion']])\n",
    "train_y = ohec.transform(df_train_map[['emotion']]).toarray()\n",
    "test_y = ohec.transform(df_test_map[['emotion']]).toarray()\n",
    "print(ohec.categories_)\n",
    "# lbec.inverse_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_map['fullpath'] = RAW_PATH + '/' + df_train_map['source'] + '/' + df_train_map['name']\n",
    "df_test_map['fullpath'] = RAW_PATH + '/' + df_test_map['source'] + '/' + df_test_map['name']\n",
    "ls_train_fullpath = df_train_map['fullpath'].tolist()\n",
    "ls_test_fullpath = df_test_map['fullpath'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Get Train Features:   9%|▉         | 1874/20310 [01:11<11:38, 26.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/TIM/lib/python3.8/multiprocessing/pool.py:851\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 851\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[1;32m    852\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pool \u001b[39m=\u001b[39m Pool(THREADS)\n\u001b[0;32m----> 2\u001b[0m train_X \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(tqdm(pool\u001b[39m.\u001b[39;49mimap(get_feature, ls_train_fullpath), total\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(ls_train_fullpath), desc\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mGet Train Features\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      3\u001b[0m train_X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(train_X)\n\u001b[1;32m      5\u001b[0m test_X \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(tqdm(pool\u001b[39m.\u001b[39mimap(get_feature, ls_test_fullpath), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(ls_test_fullpath), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGet Test Features\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/TIM/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/TIM/lib/python3.8/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    857\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m~/miniconda3/envs/TIM/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pool = Pool(THREADS)\n",
    "train_X = list(tqdm(pool.imap(get_feature, ls_train_fullpath), total=len(ls_train_fullpath), desc='Get Train Features'))\n",
    "train_X = np.array(train_X)\n",
    "\n",
    "test_X = list(tqdm(pool.imap(get_feature, ls_test_fullpath), total=len(ls_test_fullpath), desc='Get Test Features'))\n",
    "test_X = np.array(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_feature('../RawData/crema_d/1001_DFA_ANG_XX.wav').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20310, 196, 39)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('MERGE_TRAIN.npy'), {'x': train_X, 'y': train_y}, allow_pickle=True)\n",
    "np.save(os.path.join('MERGE_TEST.npy'), {'x': test_X, 'y': test_y}, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
